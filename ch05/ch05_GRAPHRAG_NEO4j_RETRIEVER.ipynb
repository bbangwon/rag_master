{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e61c945",
   "metadata": {},
   "source": [
    "- 랭체인을 활용하여 해당 그래프 DB에서 데이터를 검색하고 활용해보겠습니다.\n",
    "- 로컬검색과 글로벌검색을 직접 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074d8499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_AUTH = (os.getenv(\"NEO4J_USERNAME\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
    "NEO4J_DATABASE = \"neo4j\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e97522",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Neo4j 그래프 객체 생성\n",
    "graph = Neo4jVector.from_existing_graph(\n",
    "    embedding=embedding,\n",
    "    node_label=\"__Entity__\",\n",
    "    text_node_properties=[\"description\"],\n",
    "    embedding_node_property=\"embedding\",\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_AUTH[0],\n",
    "    password=NEO4J_AUTH[1],\n",
    ")\n",
    "\n",
    "# Neo4j Graph 겍체 추가 생성\n",
    "neo4j_graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_AUTH[0],\n",
    "    password=NEO4J_AUTH[1],\n",
    "    database=NEO4J_DATABASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011852f6",
   "metadata": {},
   "source": [
    "- 먼저 로컬 검색을 구현해보겠습니다.\n",
    "- 로컬 검색은 사용자의 질문과 가장 관련성이 높은 엔티티들을 중심으로 답변을 생성하는 방식입니다.\n",
    "- 따라서 임베딩된 질문과 가장 유사한 엔티티들을 찾은 후, 해당 엔티티와 연관된 다양한 정보를 수집해야 합니다.\n",
    "- 첫 단계로 엔티티와 연관된 다양한 정보를 수집하는 함수를 정의합니다.\n",
    "- 해당 엔티티와 연결된 텍스트 청크, 커뮤니티 보고서 그리고 관련된 다른 엔티티 정보를 조회합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7510c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_entity_context(entity_name):\n",
    "    context = {\"name\": entity_name}\n",
    "    try:\n",
    "        #텍스트 청크 가져오기\n",
    "        chunk_query = \"\"\"\n",
    "        MATCH (e: __Entity__ {name: $entity_name})<-[:HAS_ENTITY]-(c:__Chunk__)\n",
    "        RETURN c.text AS text\n",
    "        \"\"\"\n",
    "        chunk_result = neo4j_graph.query(chunk_query, {\"entity_name\": entity_name})\n",
    "        context[\"text_chunks\"] = [r[\"text\"] for r in chunk_result] if chunk_result else [\"No text chunk available\"]\n",
    "\n",
    "        # 커뮤니티 보고서 가져오기\n",
    "        community_query = \"\"\"\n",
    "        MATCH (e: __Entity__ {name: $entity_name})-[:IN_COMMUNITY]->(com: __Community__)\n",
    "        RETURN com.full_content AS report\n",
    "        \"\"\"\n",
    "        community_result = neo4j_graph.query(community_query, {\"entity_name\": entity_name})\n",
    "        context[\"community_reports\"] = [r[\"report\"] for r in community_result] if community_result else [\"No community report available\"]\n",
    "\n",
    "        # 관련 엔티티 가져오기\n",
    "        related_query = \"\"\"\n",
    "        MATCH (e: __Entity__ {name: $entity_name})-[:RELATED]-> (related: __Entity__)\n",
    "        RETURN related.name AS name, related.description AS description\n",
    "        \"\"\"\n",
    "        related_result = neo4j_graph.query(related_query, {\"entity_name\": entity_name})\n",
    "        context[\"related_entities\"] = (\n",
    "            [{\"name\": r[\"name\"], \"description\": r[\"description\"]} for r in related_result]\n",
    "            if related_result else []\n",
    "        )\n",
    "    except Exception as e:\n",
    "        context[\"error\"] = f\"Error fetching context: {str(e)}\"\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6854cc3",
   "metadata": {},
   "source": [
    "- 다음으로 수집된 정보를 읽기 쉬운 구조로 정리하는 create_structured_context 함수를 정의하여, 여러 엔티티의 정보를 하나의 통합된 텍스트로 변환할 수 있도록합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a812e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_structured_context(all_contexts, query):\n",
    "    context_str = \"## 질문과 관련된 엔티티 정보\\n\\n\"\n",
    "    context_str += \"아래는 질문에 답변하는 데 유용한 엔티티들의 구조화된 정보입니다:\\n\\n\"\n",
    "\n",
    "    for i, ctx in enumerate(all_contexts, 1):\n",
    "        context_str += f\"### 엔티티 {i}: {ctx['name']}\\n\"\n",
    "        context_str += f\"- **설명**: {ctx['description']}\\n\"\n",
    "        context_str += f\"- **텍스트 청크**:\\n\"\n",
    "        for chunk in ctx[\"text_chunks\"]:\n",
    "            context_str += f\"  - {chunk}\\n\"\n",
    "        context_str += f\"- **커뮤니티 보고서**:\\n\"\n",
    "        for report in ctx[\"community_reports\"]:\n",
    "            context_str += f\"  - {report}\\n\"\n",
    "        if ctx[\"related_entities\"]:\n",
    "            context_str += \"- **관련 엔티티**:\\n\"\n",
    "            for rel in ctx[\"related_entities\"]:\n",
    "                context_str += f\"  - {rel['name']}: {rel['description']}\\n\"\n",
    "        else:\n",
    "            context_str += \"- **관련 엔티티**: 없음\\n\"\n",
    "        context_str += \"\\n\"\n",
    "    return context_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3effcf",
   "metadata": {},
   "source": [
    "- 이제 사용할 대규모 언어 모델을 설정하고, 생성해놓은 Neo4j 그래프 객체를 리트리버로 지정하여 정보 검색에 활용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a67148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "#리트리버 설정\n",
    "retriever = graph.as_retriever(search_typye=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c40195",
   "metadata": {},
   "source": [
    "- 전체 질의응답 흐름을 구현합니다.\n",
    "- 벡터 스토어를 활용해 리트리버를 구성하여 질문과 유사한 엔티티를 검색합니다.\n",
    "- 검색된 엔티티에 대해 fetch_entity_context 함수를 호출해 텍스트 청크, 커뮤니티 보고서, 관련 엔티티 정보를 수집\n",
    "- 이를 기반으로 create_structured_context함수를 통해 구조화된 컨텍스트를 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2390aa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response:\n",
      "마일당 순이익(NET INCOME PER MILE) 분석은 투자자에게 여러 중요한 요소를 고려하는 과정입니다. 이 지표는 특정 투자에서 발생하는 순이익을 마일 단위로 나눈 값으로, 투자 수익성을 평가하는 데 유용합니다. 아래는 마일당 순이익을 효과적으로 분석하기 위해 고려해야 할 몇 가지 주요 포인트입니다:\n",
      "\n",
      "1. **수익성 평가**: 마일당 순이익은 각 마일에 대해 얼마나 많은 순이익을 얻고 있는지를 나타내므로, 이는 투자 수익성을 직접적으로 평가하는 데 유용합니다. 투자자들은 이 값을 통해 특정 투자의 효율성을 비교할 수 있습니다.\n",
      "\n",
      "2. **비용 분석**: 순이익을 계산할 때 발생하는 비용을 면밀히 분석해야 합니다. 여기에는 운영비용, 유지보수비용, 기타 관련 비용이 포함됩니다. 비용을 명확히 이해함으로써 마일당 순이익을 보다 정확하게 산출할 수 있습니다.\n",
      "\n",
      "3. **투자 전략과의 연계**: 마일당 순이익을 분석할 때, 투자자의 다른 투자 전략과의 연계성을 고려해야 합니다. 이를 통해 특정 투자가 전체 포트폴리오에 어떻게 영향을 미칠지를 평가할 수 있습니다.\n",
      "\n",
      "4. **시장 동향**: 마일당 순이익에는 시장의 변화나 외부 경제 요인도 영향을 미칠 수 있으므로, 이러한 시장 동향을 따라가는 것이 중요합니다.\n",
      "\n",
      "5. **위험 관리**: 높은 마일당 순이익이 항상 안정성이나 안전성을 보장하는 것은 아닙니다. 따라서, 투자자는 위험 요소를 충분히 이해하고 관리하여 최적의 결정을 내려야 합니다.\n",
      "\n",
      "이러한 요소들을 종합적으로 고려하면 마일당 순이익 분석을 통해 더 나은 투자 결정을 내릴 수 있으며, 궁극적으로 재정적인 목표를 달성하는 데 큰 도움이 될 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# 질문 설정\n",
    "query = \"마일당 순이익(NET INCOME PER MILE)을 어떻게 분석해야 하나요?\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "all_contexts = []\n",
    "for result in results:\n",
    "    entity_name = result.metadata.get(\"name\", \"Unknown\")\n",
    "    description = result.page_content\n",
    "    context = fetch_entity_context(entity_name)\n",
    "    context[\"name\"] = entity_name\n",
    "    context[\"description\"] = description\n",
    "    all_contexts.append(context)\n",
    "\n",
    "# 구조화된 컨텍스트 생성\n",
    "context_str = create_structured_context(all_contexts, query)\n",
    "\n",
    "# LLM 프롬프트 작성\n",
    "prompt = f\"아래 맥락에 기반해서, 주어진 질문에 한국어로 답하세요\\n\\n**질문**: {query}\\n\\n**맥락**\\n{context_str}\"\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(prompt)\n",
    "print(\"Final Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825ecd7",
   "metadata": {},
   "source": [
    "- 글로벌 검색을 구현해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ce1b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecb6151",
   "metadata": {},
   "source": [
    "- 글로벌 검색 구현에는 데이터셋 전체를 아우르는 질문에 대응하기 위해 맵-리듀스 방식을 채택합니다.\n",
    "- 미리 정의된 MAP_SYSTEM_PROMPT와 map_prompt를 활용해 각 커뮤니티 리포트에서 중간 응답들을 생성합니다.\n",
    "- 이 과정은 맵 단계에 해당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c8aaac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_SYSTEM_PROMPT = \"\"\"\n",
    "---역할---\n",
    "제공된 컨텍스트를 참고하여 사용자의 질문에 답하는 어시스턴트입니다.\n",
    "\n",
    "---목표---\n",
    "주어진 컨텍스트가 질문에 답하기에 적절하다면 질문에 대한 답을 한 뒤, 답변의 중요도 점수를 기입하여 JSON 형식으로 생성하세요.\n",
    "정보가 부족하면 \"모르겠습니다\"라고 답하세요.\n",
    "각 포인트는 다음을 포함해야 합니다:\n",
    "- 답변: 질문에 대한 답변\n",
    "- 중요도 점수: 0~100 사이의 정수\n",
    "데이터 참조 예:\n",
    "\"예시 문장 [Data: Reports (2, 7, 64, 46, 34, +more)]\"\n",
    "(한 참조에 5개 이상의 id는 \"+more\"를 사용)\n",
    "출력 예:\n",
    "{{\"Answer\": \"답변 [Data: Reports (보고서 id들)]\", \"score\": 점수}}\n",
    "\"\"\"\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", MAP_SYSTEM_PROMPT),\n",
    "        (\"human\", \"question: {question}\\n\\ncontext: {context}\"),\n",
    "    ]\n",
    ")\n",
    "map_chain = map_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab718b49",
   "metadata": {},
   "source": [
    "- 이어서 REDUCE_SYSTEM_PROMPT와 reduce_prompt를 통해 맵 단계에서 생성된 여러 분석가의 보고서를 종합하여 최종응답을 생성하는 리듀스 단계를 구현합니다.\n",
    "- 이 단계에서는 핵심 포인트들을 통합하여 마크다운 형식의 응답으로 재구성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5daa95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDUCE_SYSTEM_PROMPT = \"\"\"\n",
    "---역할---\n",
    "맵 단계에서 처리된 여러 결과를 종합하여 사용자의 질문에 답하는 어시스턴트입니다.\n",
    "\n",
    "---목표---\n",
    "제공된 맵 단계 결과를 바탕으로, 질문에 대한 종합적인 답변을 마크다운 형식으로 작성하세요.\n",
    "중요도 점수를 고려하여 핵심적인 결과 위주로 반영하며, 불필요한 세부 사항은 제외하세요.\n",
    "핵심 포인트와 시사점을 포함하고, 정보가 부족한 경우 \"모르겠습니다\"라고 답하세요.\n",
    "\n",
    "--맵 단계 결과--\n",
    "{report_data}\n",
    "데이터 참조 형식은 아래를 따르세요:\n",
    "예시 문장 [Data: Reports (2, 7, 34, 46, 64, +more)]\n",
    "(참조 ID가 5개 이상인 경우 \"+more\"를 사용)\n",
    "대상 응답 길이 및 형식: {response_type}\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", REDUCE_SYSTEM_PROMPT),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reduce_chain = reduce_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e551a0f5",
   "metadata": {},
   "source": [
    "- 글로벌 검색 함수를 구현합니다.\n",
    "- Neo4jGraph를 통해 특정 레벨의 커뮤니티 리포트를 조회한 뒤, 각 리포트에 대해 맵 체인을 적용하고 그 결과를 리듀스 체인으로 통합하여 최종 답변을 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2b0c22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing communities: 100%|██████████| 37/37 [01:34<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제공된 데이터를 종합해보면, 책의 주제는 다음과 같이 다양합니다. 주요 주제들은 다음과 같습니다:\n",
      "\n",
      "1. **철도 산업**: 미국의 철도 산업과 그것을 규제하는 간섭통상위원회(ICC)의 역할, 주요 철도 회사들의 재정 구조 및 상호 의존성, 철도의 금융 관행 등이 다뤄집니다. 이는 국가의 교통망에서 철도가 가진 중요성을 강조하고 있습니다. \n",
      "   - **관련 데이터**: 철도 산업과 관련된 다양한 재무 지표, 금융 상품, 재조직화 과정 등이 포함됩니다. [Data: Reports (1, 4, 8, 12, 19)]\n",
      "\n",
      "2. **투자 전략**: 투자 원칙과 전략, 특히 투자자들이 복잡한 투자 환경을 극복하고 자산을 최적화하는 방법에 대해 논의합니다. 금융 상품 간의 연관성과 투자자 신뢰의 중요성도 강조되고 있습니다.\n",
      "   - **관련 데이터**: 유가증권과 관련된 투자 전략 및 개인 투자자와 재무 자문가 간의 상호작용도 포함됩니다. [Data: Reports (2, 9, 11, 18)]\n",
      "\n",
      "3. **경제 동향**: 경제 성장과 투자 기회, 일반 경제 조건과 투자 결정 간의 상호 작용에 대한 논의가 이루어집니다. 다양한 금융 요소들의 관계와 경제적 요인이 시장 성과에 미치는 영향을 분석합니다.\n",
      "   - **관련 데이터**: 경제 조건과 투자 결정의 상호 작용이 포함되며, 투자 관리가 기업 재무 건강에 미치는 영향도 다룹니다. [Data: Reports (3, 5, 14)]\n",
      "\n",
      "4. **전자 문학 및 민주화**: Project Gutenberg와 관련하여 전자 문학의 자유 배급과 민주화를 주제로 하는 내용도 포함됩니다. [Data: Reports (20, 22, 23)]\n",
      "\n",
      "이처럼 이 책은 철도 산업, 투자 전략, 경제 동향, 전자 문학과 같은 다양한 주제를 포괄하고 있으며, 각 주제는 서로 연결되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "response_type: str = \"multiple paragraphs\"\n",
    "\n",
    "def global_retriever(query: str, level: int, response_type: str = response_type) -> str:\n",
    "    community_data = graph.query(\n",
    "        \"\"\"\n",
    "        MATCH (c: __Community__)\n",
    "        WHERE c.level = $level\n",
    "        RETURN c.full_content AS output\n",
    "        \"\"\",\n",
    "        params={\"level\": level},\n",
    "    )\n",
    "    intermediate_results = []\n",
    "    for community in tqdm(community_data, desc=\"Processing communities\"):\n",
    "        intermediate_result = map_chain.invoke(\n",
    "            {\n",
    "                \"question\": query,\n",
    "                \"context\": community[\"output\"],\n",
    "            }\n",
    "        )\n",
    "        intermediate_results.append(intermediate_result)\n",
    "\n",
    "    final_reponse = reduce_chain.invoke(\n",
    "        {\n",
    "            \"report_data\": intermediate_results,\n",
    "            \"question\": query,\n",
    "            \"response_type\": response_type,\n",
    "        }\n",
    "    )\n",
    "    return final_reponse\n",
    "\n",
    "print(global_retriever(\"이 책 주제가 뭐야?\", 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
