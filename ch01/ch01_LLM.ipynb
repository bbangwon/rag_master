{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c273e840",
   "metadata": {},
   "source": [
    "# 대규모 언어 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3715c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0784b",
   "metadata": {},
   "source": [
    "## 오픈AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baf9df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3a137aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본 오픈AI 클라이언트 사용\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab5d317e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"안녕하세요!\" 메시지를 보내고 응답을 받음\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"안녕하세요!\"}],\n",
    ")\n",
    "response.choices[0].message.content  # 응답 메시지 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5443f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요청에 사용할 프롬프트 템플릿 정의\n",
    "prompt_template = \"주제 {topic}에 대해 짧은 설명을 해주세요.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21195c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지를 보내고 모델의 응답을 받는 함수\n",
    "def call_chat_model(messages: List[dict]):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a33b18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'더블딥(Double Dip)은 경제학에서 주로 사용되는 용어로, 경기침체 후 회복이 일어났다가 다시 경기침체에 빠지는 현상을 의미합니다. 즉, 일시적인 경기 회복이 있은 후 다시 경제 지표가 악화되어 두 번째 침체가 발생하는 경우를 가리킵니다. 이는 소비자 신뢰나 기업 투자 등이 완전히 회복되지 않은 상태에서 일어날 수 있으며, 일반적으로 경제 정책의 효과를 평가하는 데 중요한 신호로 여겨집니다.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 주제에 따라 설명을 요청하는 함수\n",
    "def invoke_chain(topic: str):\n",
    "    prompt_value = prompt_template.format(topic=topic)\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt_value}]\n",
    "    return call_chat_model(messages)\n",
    "# \"더블딥\" 주제로 설명 요청\n",
    "invoke_chain(\"더블딥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aaa80a",
   "metadata": {},
   "source": [
    "## 랭체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52c8871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab055ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 주제에 대해 짧은 설명을 요청하는 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"주제 {topic}에 대해 짧은 설명을 해주세요.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "543cc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#출력 파서를 문자열로 설정\n",
    "output_parser = StrOutputParser()\n",
    "# 오픈AI git-4o-mini 모델을 사용하여 채팅 모델 설정\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269aabfa",
   "metadata": {},
   "source": [
    "StrOutputParser() : 모델이 반환하는 응답을 문자열로 처리할 수 있도록 처리, 문자열 응답만 추출하여 반환환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00aeda73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"더블딥\"은 경제학에서 사용되는 용어로, 경기 침체가 두 번 발생하는 상황을 의미합니다. 일반적으로 첫 번째 침체 후 약간의 회복이 있긴 하지만, 그 회복이 오래 가지 않고 다시 경기가 하락하는 상황을 지칭합니다. 이러한 현상은 주로 소비자 신뢰, 고용, 투자 등 여러 경제 지표가 불확실한 경우에 발생하며, 이로 인해 경기가 더욱 악화될 수 있습니다. 더블딥은 특히 금융 위기나 경제적 충격이 발생한 후에 자주 나타날 수 있습니다.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이프라인 설정: 주제를 받아 프롬프트를 생성하고, 모델로 응답을 생성한 후 문자열로 파싱\n",
    "chain = (\n",
    "    {\"topic\": RunnablePassthrough()}    # 입력받은 주제를 그대로 통과시킴\n",
    "    | prompt    #프롬프트 템플릿 적용\n",
    "    | model    #모델에 프롬프트를 전달하여 응답 생성\n",
    "    | output_parser    #응답을 문자열로 파싱\n",
    ")\n",
    "# 더블딥 주제로 설명 요청\n",
    "chain.invoke({\"topic\": \"더블딥\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd036c",
   "metadata": {},
   "source": [
    "### 오픈AI와 랭체인 비교\n",
    "\n",
    "|항목|오픈AI API|랭체인|\n",
    "|:--:|:--:|:--:|\n",
    "|구조|단순한  호출 방식| 모듈화된 체인구조|\n",
    "|유연성|낮음:특정 모델 종속|높음: 다양한 모델 전환 및 기능 확장 가능|\n",
    "|코드 복잡도|간단함: 코드 길이 짧음|체계적이지만 다소 길어질 수 있음|\n",
    "|재사용성|낮음: 코드 일부를 수정해야 재사용 가능| 높음: 모듈화된 구성으로 손쉽게 재사용 가능|\n",
    "|사용사례|간단한 작업|복잡하고 확장 가능한 작업|\n",
    "|모델 전환 용이성|제한적: 코드 수정 필요|매우용이: 모델 클래스를 바꾸는 것만으로 전환 가능|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e133414",
   "metadata": {},
   "source": [
    "## 대규모 언어 모델 파라미터 설정\n",
    "하이퍼파라미터(속성값) : 모델이 생성하는 텍스트의 스타일, 길이, 정확도등에 영향을 줌. 출력을 최적화.\n",
    "- 온도(temperature) \n",
    "  - 생성하는 텍스트의 다양성. \n",
    "  - 0~1 사이의 값. \n",
    "  - 작을수록 예측 가능하고 클수록 다양하고 창의적인 출력 생성\n",
    "- 최대 토큰수(Max Tokens)\n",
    "  - 생성할 최대 토큰수 지정하여 생성할 텍스트의 길이를 제한\n",
    "- 최상위 P(Top P)\n",
    "  - 생성 과정에서 특정 확률 분포 내에서 상위 P%의 토큰만을 고려하는 방식\n",
    "  - 출력의 다양성을 조정하는 데 도움\n",
    "- 빈도 패널티(Frequency Penalty)\n",
    "  - 0~1 사이의 값\n",
    "  - 값이 클수록 이미 등장한 단어나 구절이 다시 등장할 확률을 감소\n",
    "  - 반복을 줄이고 텍스트의 다양성을 증가\n",
    "- 존재 패널티(Presence Penalty)\n",
    "  - 텍스트 내에서 단어의 존재 유무에 따라 해당 단어의 선택 확률을 조정\n",
    "  - 0~1값\n",
    "  - 값이 클수록 텍스트에 등장하지 않은 새로운 단어 사용을 장려\n",
    "- 정지 시퀀스(Stop Sequences)\n",
    "  - 특정 단어나 구절이 등장할 경우 생성을 멈추도록 설정\n",
    "  - 출력을 특정 포인트에서 종료하고자 할때 사용\n",
    "\n",
    "**사용예제**\n",
    "```python\n",
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(\n",
    "    temperature=0.7,    #온도 설정(0~1)\n",
    "    max_tokens=100, #최대 토큰수\n",
    "    model_name=\"text-davinci-002\"   #사용할 모델\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80997162",
   "metadata": {},
   "source": [
    "### LogicKor 리더보드\n",
    "https://lk.instruct.kr/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
